---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hi! I will be a Ph.D. student at the Centre for Computational Data Science (CCDS) at Nanyang Technological University (NTU), supervised by [Professor Han Yu](https://sites.google.com/site/hanyushomepage/home) at Trustworthy Federated Ubiquitous Learning Research Lab [(TrustFUL)](https://trustful.federated-learning.org/) from Aug. 2025.

Before joining NTU, I completed my Master's degree in Electronic Information at Department of Computer Science and Engineering of [Shanghai Jiao Tong University](https://en.sjtu.edu.cn/), supervised by [Prof. Hongtao Lu](https://scholar.google.com/citations?user=GtNuBJcAAAAJ) at [BCMI Lab](https://bcmi.sjtu.edu.cn/index.html). I received my bachelor's degree from Shanghai Jiao Tong University in 2022. Previously, I was a visiting student at [LV-Lab](http://lv-nus.org/), ECE, National University of Singapore, supervised by [Prof. Xinchao Wang](https://sites.google.com/site/sitexinchaowang/). Here is my [CV](./Suizhi_Huang_CV_photo.pdf).

My primary areas of research interest include federated learning, computer vision, multi-task learning, generative model and weight space learning. I have published several papers at international conferences and journals with total Google Scholar citations<img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations">.


# 🔥 News
- *2025.06*: &nbsp;🎉🎉 One paper accepted by **ICCV 2025**!
- *2025.05*: &nbsp;🎉🎉 One paper accepted by **ICML 2025**!
- *2025.04*: &nbsp;🎉🎉 One paper selected as **Highlight** for **CVPR 2025**! See you in Nashville!
- *2025.02*: &nbsp;🎉🎉 One paper accepted by **CVPR 2025**!
- *2024.11*: &nbsp;🎉🎉 One paper accepted by **WSDM 2024**!
- *2024.05*: &nbsp;🎉🎉 One paper accepted by **TCSVT 2024**!
- *2024.04*: &nbsp;🎉🎉 One paper accepted by **ICMR 2024**!
- *2024.03*: &nbsp;🎉🎉 One paper accepted by **ICME 2024**!
- *2024.03*: &nbsp;🎉🎉 Three paper has been selected for **Oral** presentation at **ICASSP 2024**！
- *2024.02*: &nbsp;🎉🎉 One paper accepted by **CVPR 2024**! See you in Seattle!
- *2023.12*: &nbsp;🎉🎉 Three paper accepted by **ICASSP 2024**! See you in Seoul!

# 📖 Educations
- *2022.09 - 2025.03*, **Master of Engineering** in Electronic Information, Shanghai Jiao Tong University, China.
- *2024.08 - 2024.11*, **Visiting Student** at LV-Lab, ECE, National University of Singapore, Singapore.
- *2018.09 - 2022.06*, **Bachelor of Arts** in French, **Bachelor of Engineering** in Information Engineering, Shanghai Jiao Tong University, China.


# 📝 Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2025</div><img src='images/EquiGen.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**[Few-shot Implicit Function Generation via Equivariance](https://arxiv.org/abs/2501.01601)**

**Suizhi Huang**, Xingyi Yang, Hongtao Lu, Xinchao Wang

IEEE/CVF Conference on Computer Vision and Pattern Recognition **(CVPR) 2025 Highlight**<br>
[code](https://github.com/JeanDiable/EquiGen),
[web page](https://jeandiable.github.io/EquiGen/)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/fedhca2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**[FedHCA$^2$ : Towards Hetero-Client Federated Multi-Task Learning](https://openaccess.thecvf.com/content/CVPR2024/html/Lu_FedHCA2_Towards_Hetero-Client_Federated_Multi-Task_Learning_CVPR_2024_paper.html)**

Yuxiang Lu$^*$, **Suizhi Huang$^\*$**, Yuwen Yang, Shalayiding Sirejiding, Yue Ding, Hongtao Lu **(co-first author)**

IEEE/CVF Conference on Computer Vision and Pattern Recognition **(CVPR) 2024**
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP 2024</div><img src='images/yolomed.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**[YOLO-MED : Multi-Task Interaction Network for Biomedical Images](https://ieeexplore.ieee.org/abstract/document/10446165/)**

**Suizhi Huang**, Shalayiding Sirejiding, Yuxiang Lu, Yue Ding, Leheng Liu, Hui Zhou, Hongtao Lu

IEEE International Conference on Acoustics, Speech and Signal Processing **(ICASSP) 2024 Oral**
</div>
</div>

- **[BECAME: BayEsian Continual Learning with Adaptive Model MErging](https://arxiv.org/abs/2504.02666)**
  
  Mei Li, Yuxiang Lu, Qinyan Dai, **Suizhi Huang**, Yue Ding, Hongtao Lu
  
  International Conference on Machine Learning **(ICML) 2025**

- **[Differentiable Gaussian Representation for Incomplete CT Reconstruction](https://arxiv.org/abs/2411.04844)**
  
  Shaokai Wu, Yuxiang Lu, Wei Ji, **Suizhi Huang**, Fengyu Yang, Shalayiding Sirejiding, Qichen He, Jing Tong, Yanbiao Ji, Yue Ding, Hongtao Lu
  
  International Conference on Computer Vision, **ICCV 2025**


- **[UNIDEAL: Curriculum Knowledge Distillation Federated Learning](https://ieeexplore.ieee.org/abstract/document/10447769/)**
  
  Yuwen Yang, Chang Liu, Xun Cai, **Suizhi Huang**, Hongtao Lu, Yue Ding
  
  IEEE International Conference on Acoustics, Speech and Signal Processing **(ICASSP) 2024 Oral**

- **[Task Indicating Transformer for Task-conditional Dense Predictions](https://ieeexplore.ieee.org/abstract/document/10445743/)**
  
  Yuxiang Lu, Shalayiding Sirejiding, Yue Ding, Bayram Bayramli, **Suizhi Huang**, Hongtao Lu
  
  IEEE International Conference on Acoustics, Speech and Signal Processing **(ICASSP) 2024 Oral**

- **[BARTENDER: A Simple Baseline Model for Task-level Heterogeneous Federated Learning](https://ieeexplore.ieee.org/abstract/document/10688296/)**
  
  Yuwen Yang, Yuxiang Lu, **Suizhi Huang**, Shalayiding Sirejiding, Chang Liu, Muyang Yi, Zhaozhi Xie, Yue Ding, Hongtao Lu
  
  IEEE International Conference on Multimedia and Expo **(ICME) 2024**

- **[Federated Multi-Task Learning on Non-IID Data Silos: An Experimental Study](https://dl.acm.org/doi/abs/10.1145/3652583.3657999)**
  
  Yuwen Yang, Yuxiang Lu, **Suizhi Huang**, Shalayiding Sirejiding, Hongtao Lu, Yue Ding
  
  ACM SIGMM International Conference on Multimedia Retrieval **(ICMR) 2024**

- **[Adaptive Task-Wise Message Passing for Multi-Task Learning: A Spatial Interaction Perspective](https://ieeexplore.ieee.org/abstract/document/10528326)**
  
  Shalayiding Sirejiding, Bayram Bayramli, Yuxiang Lu, **Suizhi Huang**, Hongtao Lu, Yue Ding
  
  IEEE Transactions on Circuits and Systems for Video Technology **(TCSVT) 2024**

- **[Optimization of convolutional neural networks for background suppression in the PandaX-III experiment](https://iopscience.iop.org/article/10.1088/1361-6471/acfe24)**
  
  Shangning Xia, **Suizhi Huang**, Kexin Xu, Tao Li, Xun Chen, Ke Han, Shaobo Wang
  
  Journal of Physics G: Nuclear and Particle Physics 2023
  
# 🎖 Honors and Awards
- *2025.12* Outstanding Graduate of Shanghai (top 5% in Shanghai)
- *2024.11* National Scholarship of Graduate (top 1% national-wide)
- *2022-2024* First-Class Master's Academic Scholarship
- *2024.01* Huatai Securities Science and Technology Scholarship
- *2022.06* Outstanding Graduate of SJTU
- *2021.10 & 2019.10* Outstanding Student of SJTU
- *2020 & 2021* SJTU School Scholarship
- *2019* SJTU SPEIT ARDIAN Enterprise Scholarship

# 📚 Services
- *2025* ACMMM, ICME, CVPR, ICCV Reviewer
- *2024* NeurIPS, CVPR, ICONIP, ICME, PRML Reviewer
- *2023.09 - 2024.06* TA, Physics, SPEIT, SJTU

# 🔨 Skills
- **Programming Languages**: Python, C/C++
- **Platform**: Linux, Windows, Docker
- **Development**: PyTorch, OpenCV, Git, CUDA
- **English Proficiency**: TOEFL iBT: 111
- **French Proficiency**: DELF B2
- **Document Writing**: LaTeX, Markdown 
